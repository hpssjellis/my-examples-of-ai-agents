<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>WebGPU MLC LLM Demo</title>
<!--  <script src="https://cdn.jsdelivr.net/npm/transformer-js@0.0.9/lib/index.min.js"></script>  -->


  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 20px;
      text-align: center;
    }
    textarea {
      width: 90%;
      height: 100px;
      margin-bottom: 10px;
    }
    div {
      margin-top: 10px;
    }
  </style>
</head>
<body>
  <h1>MLC LLM WebGPU Demo</h1>
  <textarea id="myInputText" placeholder="Enter your prompt here..."></textarea><br>
  <input type="button" value="Generate Text" onclick="myGenerateText()">
  <div id="myOutput"></div>

  <script type="module">
    import { pipeline } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers@2.17.2';

    let myModel;

    async function myLoadModel() {
      const myOutputDiv = document.getElementById("myOutput");
      myOutputDiv.innerHTML = "Loading model...";
      try {
        // Load a small MLC LLM (Hugging Face model)
        myModel = await transformer.load({
          model: "Xenova/llm-mini", // Replace with a smaller compatible model
          revision: "main",
          tokenizer: "Xenova/llm-mini",
          backend: "webgpu"
        });
        myOutputDiv.innerHTML = "Model loaded successfully!";
      } catch (error) {
        myOutputDiv.innerHTML = "Error loading model: " + error.message;
        console.log(error);
      }
    }

    async function myGenerateText() {
      const myInputText = document.getElementById("myInputText").value.trim();
      const myOutputDiv = document.getElementById("myOutput");
      if (!myModel) {
        myOutputDiv.innerHTML = "Model not loaded yet. Please wait...";
        return;
      }
      if (!myInputText) {
        myOutputDiv.innerHTML = "Please enter a prompt!";
        return;
      }

      myOutputDiv.innerHTML = "Generating text...";
      try {
        const myResult = await myModel.generate(myInputText, {
          max_new_tokens: 50,
          temperature: 0.7
        });
        myOutputDiv.innerHTML = `<strong>Generated Text:</strong> ${myResult.generated_text}`;
      } catch (error) {
        myOutputDiv.innerHTML = "Error generating text: " + error.message;
        console.error(error);
      }
    }

    // Load the model when the page loads
    window.onload = myLoadModel;
  </script>

  By Jeremy Ellis, Use at your own risk. Careful if it has big files to download.<br>
  A good resource at <a href="https://www.npmjs.com/package/@xenova/transformers?activeTab=readme">https://www.npmjs.com/package/@xenova/transformers?activeTab=readme</a><br>
  My github demo pages at <a href="https://hpssjellis.github.io/my-examples-of-ai-agents/public/index.html">https://hpssjellis.github.io/my-examples-of-ai-agents/public/index.html</a>
  exxample smol <a href="https://huggingface.co/spaces/HuggingFaceTB/SmolLM-360M-Instruct-WebGPU">https://huggingface.co/spaces/HuggingFaceTB/SmolLM-360M-Instruct-WebGPU</a>
  Github for it at <a href="https://github.com/huggingface/transformers.js-examples/tree/main/smollm-webgpu">https://github.com/huggingface/transformers.js-examples/tree/main/smollm-webgpu</a>
</body>
</html>
