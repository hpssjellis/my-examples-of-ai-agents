
<!DOCTYPE html>
<html>
<head>
  <title>Bare Bones Web-LLM DeepSeek R1 Chatbot</title>
  <script type="module">
    
     // So the button can use a module function  
     window.myLoadModel  = myLoadModel
    
    import * as webllm from "https://esm.run/@mlc-ai/web-llm";

    let myEngine = new webllm.MLCEngine();

    async function myLoadModel() {
      const myModel = "DeepSeek-R1-Distill-Qwen-7B-q4f16_1-MLC";
      console.log("Loading model:", myModel);

      await myEngine.reload(myModel, { temperature: 1.0, top_p: 1 });
      console.log("Model loaded successfully!");

      const myQuestion = "What is 4+6?";
      const myMessages = [{ content: myQuestion, role: "user" }];

      console.log("Asking:", myQuestion);
      const myResponse = await myEngine.chat.completions.create({ stream: false, messages: myMessages });
      console.log("Response:", myResponse.choices[0].message.content);

    }
  </script>
</head>
<body>
  <h2>Simple Web-LLM DeepSeek R1 Chatbot</h2>
  Open console using Ctrl-Shift-i<br>
  Actually uses the MLC model DeepSeek-R1-Distill-Qwen-7B-q4f16_1-MLC 
  <input type="button" value="Load Model and Ask Question" onclick="myLoadModel()">
</body>
</html>

